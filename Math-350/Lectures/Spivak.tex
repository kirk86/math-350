\documentclass[10pt,letterpaper]{article}
\renewcommand{\rmdefault}{ptm}

\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry} 
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{polynomial}
\usepackage{layouts}
\usepackage{enumerate}
\usepackage{syntax}
\usepackage{gensymb}
\usepackage{cancel}
\usepackage{calc}
\usepackage{enumerate}
\usepackage{xcolor}
\usepackage{mdframed}

\usepackage{minted}

\usepackage[version=0.96]{pgf}
\usepackage{tikz}
\usetikzlibrary{arrows,shapes,automata,backgrounds,petri,positioning}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{decorations.shapes}
\usetikzlibrary{decorations.text}
\usetikzlibrary{decorations.fractals}
\usetikzlibrary{decorations.footprints}
\usetikzlibrary{shadows}
\usetikzlibrary{calc}
\usetikzlibrary{spy}
\usetikzlibrary{matrix}

\usepackage{tikz-qtree}

\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{4}
\usepackage[bookmarksopen,bookmarksdepth=3]{hyperref}
\usepackage{titlesec}


%define new colors
\definecolor{dark-red}{rgb}{0.8,0.15,0.15}
\definecolor{dark-blue}{rgb}{0.15,0.15,0.7}
\definecolor{medium-blue}{rgb}{0,0,0.5}
\definecolor{dark-green}{rgb}{0.2,0.7,0.7}

%set up color for table of contents
\hypersetup{
    colorlinks, linkcolor={dark-green},
    citecolor={dark-blue}, urlcolor={medium-blue}
}

\usepackage{tocloft}

%preven linebreak between subsection header and its content
\titleformat{\subsection}[runin]{\normalfont\bfseries}{\thesubsection.}{2pt}{}
%\titleformat{\section}[runin]{\normalfont\bfseries\filcenter}{\thesection.}{5pt}{}


\titleformat{\section}[block]
{\normalfont\sffamily\LARGE}
{\thesection}{.1em}{\titlerule\\[.1ex]}

%title
\title{\textbf{Important Theorems}}
\author{Introduction to Analysis}

%set numwidth of section
\setlength{\cftsecnumwidth}{1.5cm} 
%make subsection numwidth different than as section
\setlength{\cftsubsecnumwidth}{3cm}
%make subsection indent the same as section
\setlength{\cftsubsecindent}{\cftsecindent} 

\newcommand{\sol}{\textbf{Solution}}

\usepackage{tikz}
\usetikzlibrary{matrix}
\usetikzlibrary{shapes,backgrounds}

\makeatletter
\newcommand{\DESCRIPTION@original@item}{}
\let\DESCRIPTION@original@item\item
\newcommand*{\DESCRIPTION@envir}{DESCRIPTION}
\newlength{\DESCRIPTION@totalleftmargin}
\newlength{\DESCRIPTION@linewidth}
\newcommand{\DESCRIPTION@makelabel}[1]{\llap{#1}}%
\newcommand{\DESCRIPTION@item}[1][]{%
  \setlength{\@totalleftmargin}%
       {\DESCRIPTION@totalleftmargin+\widthof{\textbf{#1 }}-\leftmargin}%
  \setlength{\linewidth}
       {\DESCRIPTION@linewidth-\widthof{\textbf{#1 }}+\leftmargin}%
  \par\parshape \@ne \@totalleftmargin \linewidth
  \DESCRIPTION@original@item[\textbf{#1}]%
}
\newenvironment{DESCRIPTION}
  {\list{}{\setlength{\labelwidth}{0cm}%
           \let\makelabel\DESCRIPTION@makelabel}%
   \setlength{\DESCRIPTION@totalleftmargin}{\@totalleftmargin}%
   \setlength{\DESCRIPTION@linewidth}{\linewidth}%
   \renewcommand{\item}{\ifx\@currenvir\DESCRIPTION@envir
                           \expandafter\DESCRIPTION@item
                        \else
                           \expandafter\DESCRIPTION@original@item
                        \fi}}
  {\endlist}
\makeatother

\begin{document}
\maketitle

\setlength{\parindent}{0pt}
\setlength{\parskip}{1ex}
	\phantomsection
	\section*{{\color{red}\underline{Chapter 5. Limit}}}
	$$f(x) = 
	\begin{cases}
	0 &, x \text{ irrational } \\
	1 &, x \text{ rational } 	
	\end{cases}
	$$
	No matter what $a$ is, $f$ does not approach any number $L$ near $a$.
	
	$$f(x) = 
	\begin{cases}
	x &, x \text{ rational } \\
	0 &, x \text{ irrational } 	
	\end{cases}
	$$
	This function approaches $0$ at $0$ but does not approach any number $a \neq 0$. \\
	\textbf{Definition. } The function $f$ approaches the limit $L$ near $a$ means: for every $\epsilon > 0$,
	there is some $\delta > 0$, for all $x$ if $0 < |x - a| < \delta$, then $|f(x) - L| < \epsilon$. \\
	If it is NOT true: there is some $\epsilon > 0$ such that for every $\delta > 0$ there is some $x$ which 
	satisfies $0 < |x - a| < \delta$ but not $|f(x) - L| < \epsilon$.
	 
	\phantomsection
	\section*{{\color{red}\underline{Chapter 6. Continuous Functions}}}
	\text{Definition. } The function $f$ is continuous at $a$ if 
		$$\displaystyle\lim_{x\to a}f(x) = f(a)$$	
	$$g(x) = 
	\begin{cases}
	x \sin(1/x) &, x \neq 0 \\
	a &, x  = 0 	
	\end{cases}
	$$
	$g(x)$ is continuous at $0$.  \\
	
	$$f(x) = 
	\begin{cases}
	\sin(1/x) &, x \neq 0 \\
	a &, x  = 0 	
	\end{cases}$$
	$f(x)$ is not continuous at $0$ no matter what $a$ is because $\displaystyle\lim_{x\to 0}f(x)$ does not exists.
	
	$$h(x) = 
	\begin{cases}
	x &, x \text{ rational } \\
	0 &, x \text{ irrational }
	\end{cases}$$
	$h(x)$ is not continuous at $a$ if $a \neq 0$ since $\displaystyle\lim_{x\to a}f(x)$ does not exist. \\
	

	\textbf{Theorem 1. } If $f$ and $g$ are continuous at $a$, then
	\begin{enumerate}[(1)]
		\item $f + g$ is continuous at $a$.
		\item $f \cdot g$ is continuous at $a$.
		\item if $g(a) \neq 0$, then $\dfrac{1}{g}$ is continuous $a$.
	\end{enumerate}
	
	\textbf{Theorem 2. } If $g$ is continuous at $a$, and $f$ is continuous at $g(a)$,
	then $f \circ g$ is continuous at $a$. (Notice that $f$ is required to be continuous 
	at $g(a)$, not $a$) \\
	
	\textbf{Theorem 3. } Suppose $f$ is continuous at $a$, and $f(a) > 0$. Then $f(x) > 0$
	for all $x$ in some interval containing $a$; more precisely, there is a number $\delta > 0$
	such that $f(x) > 0$ for all $x$ satisfying $|x - a| < \delta$. Similarly, $f(a) < 0$, then
	there is a number $\delta > 0$ such that $f(x) < 0$ for all $x$ satisfying $|x - a| < \delta$. \\
	
	
	\phantomsection
	\section*{{\color{red}\underline{Chapter 7. Three Hard Theorems}}}	
	
	\textbf{Theorem 1.} If $f$ is continuous on $[a, b]$ and $f(a) < 0 < f(b)$, then there is some $x \in [a, b]$
	such that $f(x) = 0$. \\
	
	\textbf{Theorem 2.} If $f$ is continuous on $[a, b]$ and $f$ is bounded above on $[a, b]$ that is
	there is some numbers $N$ such that $f(x) \leq N$ for all $x \in [a, b]$. \\
	
	\textbf{Theorem 3.} If $f$ is continuous on $[a, b]$ then there is some number $y \in [a, b]$ such that
	$f(y) \geq f(x)$ for all $x \in [a, b]$.\\
	
	
	\textbf{Theorem 4.} If $f$ is continuous on $[a, b]$ and $f(a) < c < f(b)$ (or $f(a) > c > f(b)$ then there is some $x$ in $[a, b]$
	such that $f(x) = c$.\\
	
	\textbf{Theorem 5.} If $f$ is continuous on $[a, b]$ and $f(a) > c > f(b)$ (or $f(a) > c > f(b)$ then there is some $x$ in $[a, b]$
	such that $f(x) = c$.\\
	
	\textbf{Theorem 6.} If $f$ is continuous on $[a, b]$, then $f$ is bounded below on $[a, b]$, that is, there
	is some number $N$ such that $f(x) \geq N$ for all $x \in [a, b]$. \\
	
		
	\textbf{Theorem 7.} If $f$ is continuous on $[a, b]$, then there is some $y$ in $[a, b]$ such that
	$f(y) \leq f(x)$ for all $x$ in $[a, b]$.  \\
	
	\textbf{Theorem 8.} Every positive number has a square root. In other words, if $\alpha > 0$,
	then there is some number $x$ such that $x^2 = \alpha$. \\
	
	\textbf{Theorem 9.} If $n$ is odd, then any equation
	$$x^n + a_{n-1}x^{n-1} + \ldots + a_0 = 0$$ 
	has a root. \\
	
	\textbf{Theorem 10. } If $n$ is even and $f(x) = x^n + a_{n-1}x^{n-1} + \ldots + a_0$,
	then there is a number $y$ such that $f(y) \leq f(x)$ for all $x$. \\
	
	\textbf{Theorem 11. } Consider the equation
	$$x_n + a_{n-1}x^{n-1} + \ldots + a_0 = c \, \, \, \, \, \, \,  \, (*)$$
	and suppose $n$ is even. Then there is a number $m$ such that $(*)$ has a solution
	for $c \geq m$ and has no solution for $c < m$.		
		 
	\phantomsection
	\section*{{\color{red}\underline{Chapter 8. Least Upper Bounds}}}
	\textbf{Theorem 1. }	
	If $f$ is continuous at $a$, then there is a number $\delta > 0$ such that
	$f$ is bounded above on the interval $(a - \delta, a + \delta)$. \\
	
	\textbf{Theorem 3. } For any $\epsilon > 0$, there is natural number
	$n$ with $\dfrac{1}{n} < \epsilon$.
		
		
	\phantomsection
	\section*{{\color{red}\underline{Chapter 9. Derivative}}}
	\textbf{Definition. } The function $f$ is differentiable at $a$ if 
	$$\displaystyle\lim_{h\to 0}\dfrac{f(a+h) - f(a)}{h}$$
	exists. \\
	
	\textbf{Theorem 1.} If $f$ is differentiable at $a$, then $f$ is continuous at $a$. 
	\begin{proof}
		\begin{eqnarray*}
	\displaystyle\lim_{h\to 0} f(a + h) - f(a) &=& \displaystyle\lim_{h\to 0}
\dfrac{f(a + h) - f(a)}{h} \cdot h \\
	&=& \displaystyle\lim_{h\to 0} \dfrac{f(a + h) - f(a)}{h} \cdot \displaystyle\lim_{h\to 0}  h \\
	&=& f'(a) \cdot 0 = 0
		\end{eqnarray*}			
	\end{proof}		
	
	\phantomsection
	\section*{{\color{red}\underline{Chapter 10. Differentiation}}}
	\textbf{Theorem 1. } If $f$ is constant function, $f(x) = c$, then $f'(a) = 0$ for all numbers $a$. \\
	
	\textbf{Theorem 2. } If $f$ is identity function, $f(x) = x$, then 
	$f'(a) = 1$ for all numbers $a$. \\
	
	\textbf{Theorem 3. } If $f$ and $g$ are differentiable at $a$, then $f + g$ is also
	differentiable at $a$ and 
		$$(f + g)'(a) = f'(a) + g'(a)$$
	
	\textbf{Theorem 4. } If $f$ and $g$ are differentiable at $a$, then $f \cdot g$ is also
	differentiable at $a$, and
	$$(f \cdot g)'(a) = f'(a) \cdot g(a) + f(a) \cdot g'(a)$$
	
	
	\textbf{Theorem 5. } If $g(x) = cf(x)$ and $f$ is differentiable at $a$, then $g$ is differentiable at $a$,
	and 
	$$g'(a) = c \cdot f'(a)$$
	
	
	\textbf{Theorem 6. } If $f(x) = x^n$ for some natural number $n$, then
	$$f'(a) = na^{n-1} \text{ for all } a $$
	
	\textbf{Theorem 7. } If $g$ is differentiable at $a$, and $g(a) \neq 0$, then $1/g$
	is differentiable at $a$ and 
	$$\bigg(\dfrac{1}{g}\bigg)'(a) = \dfrac{-g'(a)}{[g(a)]^2}$$
	
	
	\textbf{Theorem 8. } If $f$ and $g$ are differentiable at $a$ and $g(a) \neq 0$, then 
	$f/g$ is differentiable at $a$ and
	$$\bigg(\dfrac{f}{g}\bigg)'(a) = \dfrac{g(a) \cdot f'(a) - f(a) \cdot g'(a)}{[g(a)]^2}$$
	
	\textbf{Theorem 9. } If $g$ is differentiable at $a$, and $f$ is differentiable at $g(a)$,
	then $f \circ g$ is differentiable at $a$, and 
	$$(f \circ g)'(a) = f'(g(a)) \cdot g'(a)$$
	
	\phantomsection
	\section*{{\color{red}\underline{Chapter 11. Significance of The Derivative}}}

	\textbf{Theorem 1. } Let $f$ be any function defined on $(a, b)$. If $x$ is a maximum (or a minimum)
	point for $f$ on $(a, b)$ and $f$ is differentiable at $x$, then $f'(x) = 0$. \\
	
	\textbf{Theorem 2. } If $x$ is a local maximum or minimum for $f$ on $(a, b)$ and $f$ is 
	differentiable at $x$, then $f'(x) = 0$. \\
	
	\textbf{Definition. } A \textbf{critical point} of a function $f$ is a number $x$ such that
	$$f'(x) = 0$$
	The number $f(x)$ itself is called a critical value of $f$. \\
	
	\underline{Note: } In order to locate the maximum and minimum of $f$ three kinds of points
	must be considered: 
	\begin{enumerate}
		\item The critical points of $f$ in $[a, b]$.
		\item The end points $a$ and $b$.
		\item Points $x$ in $[a, b]$ such that $f$ is NOT differentiable at $x$.
	\end{enumerate}		
			
	\textbf{Intermediate Value Theorem. } If $f$ is continuous on $[a, b]$ and $c$ is any number
	between $f(a)$ and $f(b)$, then there is at least one $x$ in $[a, b]$ such that $f(x) = c$. \\
	
	\textbf{Theorem 3. (Rolle's Theorem)} If $f$ is continuous on $[a, b]$ and differentiable on $(a, b)$ and $f(a) = f(b)$, 		then there is a number $x$ in $(a, b)$ such that $f'(x) = 0$. \\
	
	\textbf{Theorem 4. (The Mean Value Theorem)} If $f$ is continuous on $[a, b]$ and differentiable $(a, b)$
	then there is a number $x$ in $(a, b)$ such that
	$$f'(x) = \dfrac{f(b) - f(a)}{b - a}$$
	
	\textbf{Corollary 1. } If $f$ is defined on interval and $f'(x) = 0$ for all $x$ in the interval,
	then $f$ is constant on the interval. \\
	
	\textbf{Corollary 2. } If $f$ and $g$ are defined on the same interval, and $f'(x) = g'(x)$ for all
	$x$ in the interval, then there is some number $c$ such that $f = g + c$.\\
	
	\textbf{Corollary 3. } If $f'(x) > 0$ for all $x$ in an interval, then $f$ is increasing on the interval;
	if $f'(x) < 0$ for all $x$ in the interval, then $f$ is decreasing on the interval. \\
	
	\textbf{Theorem 5. } Suppose $f'(a) = 0$. If $f''(a) > 0$, then $f$ has a local
	minimum at $a$; if $f''(a) < 0$, then $f$ has a local maximum at $a$.
	
	\textbf{Theorem 6. } Suppose $f''(a)$ exists. If $f$ has a local minimum 
	at $a$, then $f''(a) \geq 0$; if $f$ has a local maximum at $a$, then $f''(a) \leq 0$.
	
	\textbf{Theorem 7. } Suppose that $f$ is continuous at $a$, and that $f'(x)$
	exists for all $x$ in some interval contain $a$, except perhaps for $x = a$. 
	Suppose, moreover, that $\displaystyle\lim_{x\to a}f'(x)$ exists. Then 
	$f'(a)$ also exists, and 
	$$f'(a) = \displaystyle\lim_{x\to a}f'(x)$$
	
	\textbf{Theorem 8. (The Cauchy Mean Value Theorem)} If $f$ and $g$ are continuous on $[a, b]$ and differentiable 
	on $(a, b)$, then there is a number $x$ in $(a, b)$ such that
	$$[f(b) - f(a)]g'(x) = [g(b) - g(a)]f'(x)$$
	
	
	\textbf{Theorem 9. (L'Hopital Rule)} Suppose that 
	$$\displaystyle\lim_{x\to a}f(x) = 0 \text{ and } \displaystyle\lim_{x\to a}g(x) = 0$$
	and suppose that $\displaystyle\lim_{x\to a}f'(x)/g'(x)$ exists. Then $\displaystyle\lim_{x\to a}
	f(x)/g(x)$ exists and 
	$$\displaystyle\lim_{x\to a}\dfrac{f(x)}{g(x)} = \displaystyle\lim_{x\to a}\dfrac{f'(x)}{g'(x)}$$
	
	
	\phantomsection
	\section*{{\color{red}\underline{Chapter 12. Inverse Function}}}
	\textbf{Definition. } A function is \textbf{one-one} if $f(a) \neq f(b)$ whenever $a \neq b$. \\
	
	\textbf{Definition. } For any function $f$, the inverse of $f$, denoted by $\mathbf{f^{-1}}$, is the 
	set of all pairs $(a, b)$ for which the pair $(b, a)$ is in $f$. \\
	
	\textbf{Theorem 1. } $f^{-1}$ is a function if and only $f$ is one to one.  \\
	
	\textbf{Theorem 2. } If $f$ is continuous and one-one on an interval, then $f$ is either increasing
	or decreasing on that interval.  \\
	
	\textbf{Theorem 3. } If $f$ is continuous and one-one on an interval, then $f^{-1}$ is also continuous. \\
	
	\textbf{Theorem 4. } If $f$ is continuous one-one function defined on an interval and $f'(f^{-1}(a)) = 0$,
	then $f^{-1}$ is \emph{not} differentiable at $a$.  \\
	
	\textbf{Theorem 5. } Let $f$ be a continuous one-one function defined on an interval, and suppose that
	$f$ is differentiable at $f^{-1}(b)$, withe derivative $f'(f^{-1}(b)) \neq 0$. Then $f^{-1}$ is differentiable
	at $b$, and 
	$$(f^{-1})'(b) = \dfrac{1}{f'(f^{-1}(b))}$$
	
	\phantomsection
	\section*{{\color{red}\underline{Chapter 13. Integrals}}}
	\textbf{Definition. } Let $a < b$. A \textbf{partition} of the interval $[a, b]$ is a finite collection
	of points on $[a, b]$, one of which is $a$ and one of which is $b$. \\
	
	\textbf{Definition. } Suppose $f$ is bounded on $[a, b]$ and $P = \{t_0, t_1, \ldots, t_n\}$ is a partition
	of $[a, b]$. Let
	\begin{eqnarray*}
		m_i &=& \inf\{f(x) : t_{i-1} \leq x \leq t_i\} \\
		M_i &=& \sup\{f(x) : t_{i-1} \leq x \leq t_i\}
	\end{eqnarray*}
	The lower sum of $f$ for $P$ denoted by 
	$$L(f, P) = \displaystyle\sum_{i=1}^{n} m_i(t_i - t_{i-1})$$
	The upper sum of $f$ for $P$ denoted by 
	$$U(f, P) = \displaystyle\sum_{i=1}^{n} M_i(t_i - t_{i-1})$$
	
	\textbf{Lemma. } If $Q$ contains $P$, ($P \subseteq Q$), then 
	$$L(f, P) \leq L(f, Q)$$
	$$U(f, P) \geq U(f, Q)$$
	
	\textbf{Theorem 1. } Let $P_1$ and $P_2$ be partitions of $[a, b]$ and let $f$ be a function
	which is bounded on $[a, b]$. \\ Then $L(f, P_1) \leq U(f, P_2)$. \\
	
	\textbf{Definition. } A function $f$ which is bounded on $[a, b]$ is \textbf{integrable} on $[a, b]$
	if $P$ is a partition of $[a, b]$ and 
	$$\sup\{L(f, P)\} = \inf\{U(f, P)\}$$
	In this case, this common \textbf{number} is called the \textbf{integral} of $f$ on $[a, b]$ and is denoted by
	$$\displaystyle\int_{a}^{b} f$$
	
	\textbf{Theorem 2. } If $f$ is bounded on $[a, b]$, then $f$ is integrable on $[a, b]$ if and only if
	for every $\epsilon > 0$, there is a partition $P$ of $[a, b]$ such that
	$$U(f, P) - L(f, P) < \epsilon$$
	
	\textbf{Theorem 3. } If $f$ is continuous on $[a, b]$ then $f$ is integrable on $[a, b]$. \\
	
	\textbf{Theorem 4. } Let $a < c < b$. If $f$ is integrable on $[a, b]$, then $f$ is integrable
	on $[a, c]$ and on $[c, b]$. Conversely, if $f$ is integrable on $[a, c]$ and on $[c, b]$ then 
	$f$ is integrable on $[a, b]$. Finally if $f$ is integrable on $[a, b]$ then 
	$$\displaystyle\int_{a}^{b} f = \displaystyle\int_{a}^{c} f + \displaystyle\int_{c}^{b} f$$
	
	\textbf{Theorem 5. } If $f$ and $g$ are integrable on $[a, b]$, then $f + g$ is integrable
	on $[a, b]$ and 
	$$\displaystyle\int_{a}^{b} (f + g) = \displaystyle\int_{a}^{b} f + \displaystyle\int_{a}^{b} g$$
	
	\textbf{Theorem 6. } If $f$ is integrable on $[a, b]$, then for any number $c$, the function
	$cf$ is integrable on $[a, b]$ and 
	$$\displaystyle\int_{a}^{b} cf = c \cdot \displaystyle\int_{a}^{b} f$$
	
	\textbf{Theorem 7. } Suppose $f$ is integrable on $[a, b]$ and that
	$$m \leq f(x) \leq M \text{ for all } x \in [a, b]$$
	Then 
	$$m(b - a) \leq \displaystyle\int_{a}^{b} \leq M(b - a)$$
	
	\textbf{Theorem 8. } If $f$ is integrable on $[a, b]$ and $F$ is defined on $[a, b]$
	by 
	$$F(x) = \displaystyle\int_{a}^{x} f$$
	then $F$ is continuous on $[a, b]$. \\
	
	
	\phantomsection
	\section*{{\color{red}\underline{Chapter 14. The Fundamental Theorem of Calculus}}}
	\textbf{Theorem 1. } If $f$ is integrable on $[a, b]$ and define $F$ on $[a, b]$ by
	$$F(x) = \displaystyle\int_{a}^{x} f$$
	If $f$ is continuous at $c$ in $[a, b]$, then $F$ is differentiable at $c$, and 
	$$F'(c) = f(c)$$
	
	\textbf{Corollary. } If $f$ is continuous on $[a, b]$ and $f = g'$ for some function $g$,
	then 
	$$\displaystyle\int_{a}^{b} f = g(b) - g(a)$$	
	
	\textbf{Theorem 2. } If $f$ is integrable on $[a, b]$ and $f = g'$ for some function $g$,
	then 
	$$\displaystyle\int_{a}^{b} f = g(b) - g(a)$$

	\phantomsection
	\section*{{\color{red}\underline{Chapter 15. The Trigonometric Functions}}}
	\textbf{Definition. }
	\fbox{
	\begin{minipage}{2 in}
	$$\pi = 2 \cdot \displaystyle\int_{-1}^{1} \sqrt{1 - x^2} dx$$	
	\end{minipage}	
	}
	
	\textbf{Definition. } 
	If $-1 \leq x \leq 1$ then 
	$$A(x) = \dfrac{x\sqrt{1 - x^2}}{2} + \displaystyle\int_{x}^{1} \sqrt{1 - t^2} dt$$
	
	\textbf{Definition. } 
	If $0 \leq x \leq \pi$, then $\cos(x)$ is the unique number in $[-1, 1]$ such that
	$$A(\cos(x)) = \dfrac{x}{2}$$
	and 
	$$\sin(x) = \sqrt{1 - \cos(x)^2}$$
	
	\textbf{Theorem 1. } If $0 < x < \pi$, then 
	$$\cos'(x) = -\sin(x)$$
	$$\sin'(x) = \cos(x)$$
	
	\textbf{Theorem 2. } If $x \neq k \pi + \dfrac{\pi}{2}$, then 
	$$\sec'(x) = \sec(x) \tan(x)$$
	$$\tan'(x) = \sec(x)^2$$
	If $x \neq k \pi$, then
	$$\csc'(x) = -\csc(x) \cot(x)$$
	$$\cot'(x) = -\csc(x)^2$$
	
	\textbf{Theorem 3. } If $-1 < x < 1$, then
	$$\arcsin'(x) = \dfrac{1}{\sqrt{1 - x^2}}$$
	$$\arccos'(x) = \dfrac{-1}{\sqrt{1 - x^2}}$$
	Moreover, for all $x$ we have
	$$\arctan'(x) = \dfrac{1}{1 + x^2}$$
	
	\textbf{Lemma. } Suppose $f$ has a second derivative everywhere and that
	\begin{eqnarray*}
		f'' + f &=& 0 \\
		f(0) &=& 0 \\
		f'(0) &=& 0 
	\end{eqnarray*}		
	Then $f = 0$.
	
	
	\textbf{Theorem 4. } Suppose $f$ has a second derivative everywhere and that
	\begin{eqnarray*}
		f'' + f &=& 0 \\
		f(0) &=& a \\
		f'(0) &=& b 
	\end{eqnarray*}		
	Then $f = b \cdot \sin + a \cdot \cos$
	
	\textbf{Theorem 5. } If $x$ and $y$ are any two numbers, then
	$$\sin(x + y) = \sin(x) \cos(y) + \cos(x) \sin(y)$$
	$$\cos(x + y) = \cos(x) \cos(y) - \sin(x) \sin(y)$$
	
	
	\phantomsection
	\section*{{\color{red}\underline{Chapter 20. Approximation By Polynomial Functions}}}
	\textbf{Theorem 1.} Suppose that $f$ is a function for which 
	$$f'(a), f''(a), \ldots, f^{(n)}(a)$$
	all exist. Let
	$$a_k = \dfrac{f^{(k)}(a)}{k!}  \, \, ,0 \leq k \leq n$$
	and define
	$$P_{n,a}(x) = a_0 + a_1(x - a) + \ldots + a_n(x - a)^n$$
	Then
	$$\displaystyle\lim_{x\to a} \dfrac{f(x) - P_{n,a}(x)}{(x - a)^n} = 0$$
	
	\textbf{Theorem 2. } Suppose that 
	$$f'(a) = \ldots = f^{(n-1)}(a) = 0$$
	$$f^{(n)}(a) \neq 0$$
	\begin{enumerate}[(1)]
	\item If $n$ is even and $f^{(n)}(a) > 0$, then $f$ has a local minimum at $a$.
	\item If $n$ is even and $f^{(n)}(a) < 0$, then $f$ has a local maximum at $a$.
	\item If $n$ is odd, then $f$ has neither a local maximum nor a local minimum at $a$.
	\end{enumerate}		
	
	\textbf{Definition. } 
	Two functions $f$ and $g$ are equal up to order $n$ at $a$ if 
	$$\displaystyle\lim_{x\to a}\dfrac{f(x) - g(x)}{(x - a)^n} = 0$$
	
	\textbf{Theorem 3. }
	Let $P$ and $Q$ are two polynomials in $(x - a)$, of degree $\leq n$, and suppose that
	$P$ and $Q$ are equal up to order $n$ at $a$. Then $P = Q$. \\
	
	\textbf{Corollary. } 
	Let $f$ be $n$ times differentiable at $a$, and suppose that $P$ is a polynomial in $(x - a)$
	of degree $\leq n$, which equals $f$ up to order $n$ at $a$. Then $P = P_{n,a,f}$.
	
	\textbf{Lemma. } 
	Suppose that the function $R$ is $(n + 1)$ times differentiable on $[a, b]$, and 
	$$R^{(k)} = 0 \text{ for } k = 0, 1, 2, \ldots n$$
	Then for any $x$ in $(a, b]$ we have
	$$
	\dfrac{R(x)}{(x - a)^{n+1}} = \dfrac{R^{(n+1)}(t)}{(n + 1)!} \text{ for some } t \text{ in } (a, x)$$
	
	
	\phantomsection
	\section*{{\color{red}\underline{Chapter 22. Infinite Sequence}}}
	\textbf{Definition. } An \textbf{infinite sequence} of real numbers is a function 
	whose domain is $\mathbb{N}$. \\
	
	\textbf{Definition. } A sequence $(a_n)$ converges to $L$ if for every $\epsilon > 0$,
	there is a natural number $N$ such that, for all natural number $n$,
	$$\text{if } n > N \text{ then } |a_n - L| < \epsilon$$
	
	\textbf{Theorem 1. } Let $f$ be a function defined in an open interval containing $c$,
	except perhaps at $c$ itself, with 
	$$\displaystyle\lim_{x\to c}f(x) = L$$
	Suppose $(a_n)$ is a sequence such that 
	\begin{enumerate}[(1)]
		\item Each $a_n$ is in the domain of $f$
		\item Each $a_n \neq c$
		\item $\displaystyle\lim_{n\to \infty}a_n = c$
	\end{enumerate}
	Then the sequence $(f(a_n))$ satisfies
	$$\displaystyle\lim_{n\to \infty}f(a_n) = L$$
	Conversely if this is true for every sequence $(a_n)$ satisfying the above conditions, then
	$$\displaystyle\lim_{x\to c}f(x) = L$$
	
	\textbf{Theorem 2. } If $(a_n)$ is nondecreasing and bounded above, then $(a_n)$ converges.
	Similar statement is true if $(a_n)$ is nonincreasing and bounded below. \\
	
	\textbf{Lemma. } Any sequence $(a_n)$ contains a subsequence which is either nondecreasing or
	nonincreasing. \\
	
	\textbf{Definition. } A sequence $(a_n)$ is a Cauchy Sequence if for every $\epsilon > 0$ there is
	a natural number $N$ such that for all $m, n$,
	$$\text{if } m, n > N \text{ then } |a_n - a_m| < \epsilon$$
	
	\textbf{Theorem 3. } A sequence $(a_n)$ converges if and only if it is a Cauchy Sequence. \\
	
	\textbf{Monotone Subsequence Theorem}
	If $X = (x_n)$ is a sequence of real numbers then there is a monotone subsequence. \\
	
	\textbf{Bolzano-Weierstrass Theorem} A bounded sequence of real numbers has a convergent
	subsequence. \\
	
	\textbf{Theorem} Let $X = (x_n)$ be a bounded sequence of real numbers and let $x \in \mathbb{R}$ have
	the property that every convergent subsequence of $X$ converges to $x$, then the sequence $X$
	converges to $x$. \\
	
	\phantomsection
	\section*{{\color{red}\underline{Chapter 18. The Logarithm and Exponential Functions}}} 
	\textbf{Definition. } 
	$$\log(x) = \int_1^x \dfrac{1}{t} dt$$
	
	\textbf{Theorem 1. }
	If $x, y > 0$, then $\log(xy) = \log(x) + \log(y)$.
	
	\textbf{Corollary 1.} If $n$ is natural number and $x > 0$, then
	$$\log(x^n) = n \log(x)$$
	
	\textbf{Corollary 2. } If $x, y > 0$, then 
	$$\log\bigg(\dfrac{x}{y}\bigg) = \log(x) - \log(y)$$
	
	\textbf{Definition. } 
	The exponential function, $\mathbb{\exp}$ is defined as $\log^{-1}$.
	
	\textbf{Theorem 2. } 
	For all number $x$,
	$$\exp'(x) = \exp(x)$$
	
	\textbf{Theorem 3. } 
	If $x$ and $y$ are any two numbers, then 
	$$\exp(x + y) = \exp(x) \cdot \exp(y)$$
	
	\textbf{Definition. }
	$\mathbf{e} = \exp(1)$ \\
	
	\textbf{Definition. } 
	If $a > 0$, for any real number $x$,
	$$a^x = e^{x\log(a)}$$
	
	\textbf{Theorem 4. } 
	If $a > 0$, then 
	\begin{enumerate}[(1)]
		\item $(a^b)^c = a^{bc} \text{ for } b, c$
		\item $a^1 = a$ and $a^{x+y} = a^x \cdot a^y \text{ for } x, y$.
	\end{enumerate}
	
	\textbf{Theorem 5. }
	If $f$ is differentiable and 
	$$f'(x) = f(x) \text{ for all } x$$
	then there is a number $c$ such that
	$$f(x) = ce^x \text{ for all } x$$
\begin{proof}
	Let $g(x) = \dfrac{f(x)}{e^x}$. This is permissible since $e^x \neq 0$ for all $x$. Then
	$$g'(x) = \dfrac{e^xf'(x) - f(x)e^x}{(e^x)^2} = 
	\dfrac{e^x[f(x) - f(x)]}{e^{2x}} = 	
	0$$
	Therefore there is a number $c$ such that
	$$g(x) = \dfrac{f(x)}{e^x} = c \text{ for all } x$$
\end{proof}

	\textbf{Theorem 6. } For any natural number $n$,
	$$\displaystyle\lim_{x\to \infty} \dfrac{e^x}{x^n} = \infty$$
\begin{proof}
	The proof consists of several steps:
	\begin{enumerate}[(1)]
	\item $e^x > x$ for all $x$, and consequently $\displaystyle\lim_{x\to \infty}e^x = \infty$ (this
	may be considered to be the case $n = 0$).
	To prove this statement (which is clear for $x \leq 0$) it suffices to show that
	$$x > \log(x) \text{ for all } x > 0$$
	If $x < 1$, this is clearly true, since $\log(x) < 0$. If $x > 1$, then $x - 1$ is an 
	upper sum for $f(t) = \dfrac{1}{t}$ on $[1, x]$ so $\log(x) < x - 1 < x$.
	\item $\displaystyle\lim_{x\to \infty} \dfrac{e^x}{x} = \infty$ \\
	To prove this, note that
	$$\dfrac{e^x}{x} = \dfrac{e^{x/2} \cdot e^{x/2}}{\dfrac{x}{2} \cdot 2}
	= \dfrac{1}{2} \bigg( \dfrac{e^{x/2}}{x/2} \bigg) \cdot e^{x/2}$$
	By (1), the expression in parentheses is greater than $1$, and 
	$\displaystyle\lim_{x\to \infty} e^{x/2} = \infty$; this shows that
	$\displaystyle\lim_{x\to \infty} \dfrac{e^x}{x} = \infty$.
	
	\item $\displaystyle\lim_{x\to \infty} \dfrac{e^x}{x^n} = \infty$ \\
	Note that
	$$\dfrac{e^x}{x^n} = \dfrac{(e^{x/n})^n}{(x/n)^n \cdot n^n} 
	= \dfrac{1}{n^n} \cdot \bigg( \dfrac{e^{x/n}}{x/n} \bigg)^n$$
	The expression in parentheses becomes arbitrarily large, by (2), so the $n$th
	power certainly becomes arbitrarily large.	
	
	
	\end{enumerate}
		
	
	
\end{proof}	
	

	
\end{document}
